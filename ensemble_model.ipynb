{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b392534",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-31T14:41:11.199438Z",
     "iopub.status.busy": "2023-10-31T14:41:11.198765Z",
     "iopub.status.idle": "2023-10-31T14:42:15.740874Z",
     "shell.execute_reply": "2023-10-31T14:42:15.739421Z"
    },
    "papermill": {
     "duration": 64.550737,
     "end_time": "2023-10-31T14:42:15.745266",
     "exception": false,
     "start_time": "2023-10-31T14:41:11.194529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0       7\n",
      "1       5\n",
      "2       3\n",
      "3       9\n",
      "4       5\n",
      "       ..\n",
      "8986    4\n",
      "8987    1\n",
      "8988    2\n",
      "8989    0\n",
      "8990    2\n",
      "Name: label_encoded, Length: 8991, dtype: int64\n",
      "The 'label' column is not present in train_data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 4 7 2 0 2 6 4 3 0 3 7 6 9 9 6 7 9 5 7 3 1 3 2 4 6 4 8 8 8 1 4 5 1 3 5 3\n",
      " 1 0 2 7 4 5 9 7 5 3 1 0 2 8 8 0 8 1 2 1 0 1 4 6 2 0 1 2 5 8 5 4 5 2 8 4 8\n",
      " 0 0 3 7 1 3 0 7 7 0 3 8 4 4 2 8 2 2 4 9 4 3 3 0 0 4 5 8 3 6 1 9 2 6 6 5 3\n",
      " 7 1 6 0 5 2 1 6 6 7 4 5 0 0 9 6 6 3 9 7 9 2 9 6 0 3 5 6 1 4 9 1 4 3 3 5 1\n",
      " 8 3 9 6 2 0 9 2 5 7 5 0 9 9 3 7 3 2 1 9 1 2 8 2 3 2 1 3 0 2 1 1 5 3 6 2 1\n",
      " 7 5 9 8 1 1 3 6 6 7 3 8 5 8 5 2 3 7 8 5 6 9 4 5 0 5 4 5 8 3 3 2 9 4 3 9 4\n",
      " 5 9 7 3 2 6 8 2 7 0 0 0 4 4 5 8 1 2 4 9 5 0 8 8 7 2 4 0 2 8 9 7 5 1 0 2 1\n",
      " 4 0 9 0 4 8 7 9 1 5 9 9 3 7 2 9 8 3 9 9 6 0 6 8 2 2 7 4 7 2 6 6 7 6 2 2 0\n",
      " 8 1 5 4 4 5 4 1 6 5 6 8 1 0 7 7 5 6 6 5 8 4 9 9 5 8 3 0 3 7 1 5 6 5 5 8 3\n",
      " 5 7 8 6 0 2 4 3 9 0 7 6 4 5 8 2 6 2 3 3 1 9 7 3 2 7 8 2 5 1 0 1 1 8 9 7 9\n",
      " 8 8 3 2 3 1 3 8 0 8 1 2 5 3 3 1 7 0 6 2 6 4 9 0 7 9 8 2 2 3 2 6 6 2 2 1 5\n",
      " 3 5 7 7 6 7 2 5 3 4 1 5 1 1 8 4 0 6 5 3 4 1 4 5 7 3 2 6 9 6 6 7 2 4 0 3 3\n",
      " 1 4 3 6 1 8 6 8 6 0 2 6 3 3 4 3 6 9 1 4 8 5 6 8 7 5 7 5 1 3 0 3 9 5 9 8 5\n",
      " 8 8 5 2 8 5 8 1 5 7 9 8 7 0 6 1 5 9 0 4 1 0 6 9 4 0 3 3 8 8 5 9 8 3 6 6 5\n",
      " 6 2 0 6 8 3 9 3 0 5 5 1 6 1 5 2 0 6 1 9 7 4 8 9 0 7 9 1 6 4 6 9 3 9 7 2 9\n",
      " 5 9 0 8 1 1 6 1 4 0 1 4 7 2 1 6 0 6 8 2 8 4 5 6 5 9 2 3 2 4 9 0 6 8 1 2 7\n",
      " 3 3 6 0 2 4 4 5 9 3 3 6 6 0 1 4 8 7 1 7 9 0 8 7 9 3 9 0 6 4 4 3 1 9 3 5 8\n",
      " 5 2 0 1 7 4 7 1 8 4 4 7 3 8 3 2 0 2 0 0 5 0 0 9 0 1 2 2 1 9 9 2 2 1 1 4 0\n",
      " 3 0 5 7 0 5 8 3 3 6 3 3 7 0 8 4 5 7 6 4 5 0 2 7 5 2 5 7 4 8 2 9 8 8 0 5 9\n",
      " 1 5 8 2 8 6 9 7 7 2 1 1 9 1 5 5 6 2 9 8 8 5 8 2 9 2 3 1 4 0 2 4 6 9 9 5 3\n",
      " 6 5 2 0 9 0 6 1 6 1 0 7 8 5 5 4 2 1 6 6 2 2 6 6 2 8 4 6 1 7 2 8 7 4 6 2 6\n",
      " 6 6 5 1 9 2 1 4 4 8 7 7 0 4 7 1 6 6 3 7 9 0 9 7 2 6 2 7 5 6 0 7 4 0 3 1 2\n",
      " 6 5 6 2 4 6 4 8 9 2 2 6 0 3 4 7 0 8 9 7 7 6 5 6 6 1 2 0 2 7 2 8 3 7 0 3 1\n",
      " 7 2 4 6 1 3 0 0 3 8 0 5 8 8 2 3 0 0 3 0 4 2 7 0 2 5 3 5 5 3 1 1 9 7 1 5 8\n",
      " 4 5 7 4 4 8 4 9 1 4 0 7 8 3 8 9 6 2 3 3 4 3 1 7 2 3 5 1 2 1 2 3 8 5 5 4 7\n",
      " 8 9 1 5 7 3 7 0 3 6 5 0 0 8 1 4 8 1 0 8 5 7 6 7 4 7 1 9 6 3 9 8 5 8 0 1 8\n",
      " 3 8 0 8 3 0 2 5 3 9 1 0 4 9 1 2 8 4 0 1 1 6 8 8 1 3 0 1 4 7 4 1 8 6 1 3 5]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/pes-ec-mi-competition-a/train.csv\")\n",
    "\n",
    "test_data = pd.read_csv(\"/kaggle/input/pes-ec-mi-competition-a/test.csv\")\n",
    "salary_nan_count = train_data['label'].isna().sum()\n",
    "\n",
    "print(salary_nan_count)\n",
    "\n",
    "genre_mapping = {\n",
    "    'blues': 0,\n",
    "    'classical': 1,\n",
    "    'country': 2,\n",
    "    'disco': 3,\n",
    "    'hiphop': 4,\n",
    "    'jazz': 5,\n",
    "    'metal': 6,\n",
    "    'pop': 7,\n",
    "    'reggae': 8,\n",
    "    'rock': 9\n",
    "}\n",
    "\n",
    "# Use the map function to encode the labels\n",
    "train_data['label_encoded'] = train_data['label'].map(genre_mapping)\n",
    "print(train_data['label_encoded'] )\n",
    "\n",
    "train_data.drop('label', axis=1, inplace=True)\n",
    "if 'label' in train_data.columns:\n",
    "     print(\"The 'label' column is present in train_data.\")\n",
    "else:\n",
    "    print(\"The 'label' column is not present in train_data.\")\n",
    "    \n",
    "train_data.rename(columns={'label_encoded': 'label'}, inplace=True)\n",
    "    \n",
    "# Suppress the FutureWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Feature Engineering: Add some custom features\n",
    "# For example, add a feature that calculates the sum of the first 5 features.\n",
    "X = np.column_stack((X, X[:, :5].sum(axis=1)))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "test_data = pd.read_csv('/kaggle/input/pes-ec-mi-competition-a/test.csv')\n",
    "X_train=train_data.iloc[:, 1:-1]\n",
    "X_test = test_data.iloc[:, :-1]\n",
    "y_train=train_data['label']\n",
    "# Define individual models\n",
    "#rf_model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "#ada_model = AdaBoostClassifier(n_estimators=400, random_state=42)\n",
    "#gb_model = GradientBoostingClassifier(n_estimators=500, random_state=42)\n",
    "xgb_model = XGBClassifier(learning_rate=0.1, n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create an ensemble of models using VotingClassifier\n",
    "#ensemble_model = VotingClassifier(\n",
    "  #  estimators=[('rf', rf_model), ('ada', ada_model), ('gb', gb_model)],\n",
    "   # voting='hard'\n",
    "#)\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_model), ('lr', lr_model), ('rf', rf_model)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Fit the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "print(y_pred)\n",
    "#accuracy = accuracy_score(y_test, y_pred)\n",
    "#print(\"Ensemble Model Accuracy (with Feature Engineering):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341755ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T14:42:15.757329Z",
     "iopub.status.busy": "2023-10-31T14:42:15.756479Z",
     "iopub.status.idle": "2023-10-31T14:42:15.783913Z",
     "shell.execute_reply": "2023-10-31T14:42:15.782805Z"
    },
    "papermill": {
     "duration": 0.035934,
     "end_time": "2023-10-31T14:42:15.786112",
     "exception": false,
     "start_time": "2023-10-31T14:42:15.750178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Data:\n",
      "       id  Label\n",
      "0    9586      9\n",
      "1    6984      4\n",
      "2    7047      7\n",
      "3    2510      2\n",
      "4      34      0\n",
      "..    ...    ...\n",
      "994  4583      8\n",
      "995  6045      6\n",
      "996  1897      1\n",
      "997  3565      3\n",
      "998  5685      5\n",
      "\n",
      "[999 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Generate the 'id' column with values from 0 to 99\n",
    "#ids = list(range(100))\n",
    "\n",
    "# Assuming 'test' and 'predictions_sarimax' are defined\n",
    "submission_data = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'Label': y_pred\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_data.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Print the submission DataFrame\n",
    "print(\"Submission Data:\")\n",
    "print(submission_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 68.378033,
   "end_time": "2023-10-31T14:42:16.307668",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-31T14:41:07.929635",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
